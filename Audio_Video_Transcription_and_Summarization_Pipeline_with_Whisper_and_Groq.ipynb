{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5HumPCqB1i8udN4JkJyWP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahzunorain/Audio-Video-Transcription-and-Summarization-Pipeline-with-Whisper-and-Groq/blob/main/Audio_Video_Transcription_and_Summarization_Pipeline_with_Whisper_and_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "# !pip install groq ffmpeg-python\n",
        "!pip install -q groq ffmpeg-python git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eTOfW7qGR2Nd",
        "outputId": "d7704e10-9d4c-405e-b62b-205011fbeb52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y whisper\n",
        "# !pip install -q git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "VOT2s8ZDZ1kQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "66hfbIfNfjLh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n823HkPdRyk1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ffmpeg\n",
        "import whisper\n",
        "from groq import Groq\n",
        "from google.colab import files, userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# GROQ_API_KEY = userdata.get('GROQ_API_TOKEN')"
      ],
      "metadata": {
        "id": "gjoh_aNAR7yD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install necessary libraries\n",
        "# !pip install -q git+https://github.com/openai/whisper.git\n",
        "# !pip install -q groq ffmpeg-python\n",
        "\n",
        "# import os\n",
        "# import ffmpeg\n",
        "# import whisper\n",
        "# from groq import Groq\n",
        "# from google.colab import files, userdata\n",
        "\n",
        "# Get the API key from user data\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_TOKEN')\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "\n",
        "# Upload the audio or video file\n",
        "uploaded = files.upload()  # This will allow you to upload files from your local system.\n",
        "\n",
        "# Function to extract audio from video\n",
        "def extract_audio(video_path, audio_path=\"temp_audio.wav\"):\n",
        "    \"\"\"Extracts audio from video.\"\"\"\n",
        "    try:\n",
        "        # Run ffmpeg command with stderr capture for better error handling\n",
        "        ffmpeg.input(video_path).output(audio_path).run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
        "    except ffmpeg.Error as e:\n",
        "        print(\"FFmpeg error encountered:\")\n",
        "        print(e.stderr.decode() if e.stderr else e)\n",
        "    return audio_path\n",
        "\n",
        "# Function to transcribe audio to text using Whisper model\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes audio to text using Whisper model.\"\"\"\n",
        "    model = whisper.load_model(\"base\")  # Load the Whisper model\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Function to summarize text using Groq API\n",
        "def summarize_text(text):\n",
        "    \"\"\"Summarizes text using Groq API.\"\"\"\n",
        "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"Summarize the following text: {text}\"}],\n",
        "        model=\"llama3-8b-8192\"\n",
        "    )\n",
        "    summary = response.choices[0].message.content\n",
        "    return summary\n",
        "\n",
        "# Complete function to process audio or video\n",
        "def process_media(media_path):\n",
        "    \"\"\"Processes audio or video: extracts audio, transcribes it, and summarizes the transcription.\"\"\"\n",
        "    audio_path = None\n",
        "    try:\n",
        "        # Determine if the file is a video or audio based on the file extension\n",
        "        if media_path.endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
        "            # Step 1: Extract audio from video\n",
        "            audio_path = extract_audio(media_path)\n",
        "        else:\n",
        "            audio_path = media_path  # If it's already audio, use it as is\n",
        "\n",
        "        # Step 2: Transcribe audio to text\n",
        "        transcription = transcribe_audio(audio_path)\n",
        "        print(\"Transcription:\\n\", transcription)\n",
        "\n",
        "        # Step 3: Summarize transcription\n",
        "        summary = summarize_text(transcription)\n",
        "        print(\"Summary:\\n\", summary)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the media: {e}\")\n",
        "\n",
        "    return transcription, summary\n",
        "\n",
        "# Example usage: Process the uploaded media file\n",
        "for filename in uploaded.keys():\n",
        "    transcription, summary = process_media(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "-_8Y5ATRR0GS",
        "outputId": "1d209130-dd98-4905-f2b8-2d9f65c07a8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d677c859-1855-418a-87cf-2e093a6022fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d677c859-1855-418a-87cf-2e093a6022fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PEC Abdullah Zunorain.mp4 to PEC Abdullah Zunorain (2).mp4\n",
            "Transcription:\n",
            "  Salam Aleem. My name is Abdul Laden Lauren. I am recently graduated from Utti Peshawar as an electrical engineer. I am currently working as an embedded certain engineer, trainee at Chepsol Technology. I want to express my sincere gratitude to the BC internship graduate internship program. This program provide me with reliable skills and and all experience that have been very insurant in my current role. Thank you to you, everyone, in our part, creating such a great and fantastic opportunity for our growth in learning.\n",
            "Summary:\n",
            " Abdul Laden Lauren, a recent electrical engineering graduate from University of Peshawar, is writing to express his gratitude to the BC internship graduate internship program. He mentions that the program provided him with reliable skills and valuable experience, which have been essential in his current role as an embedded systems engineer trainee at Chepsol Technology. He thanks everyone involved in creating the program, acknowledging its role in his growth and learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "QMBEuk-TcY_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install necessary libraries\n",
        "# !pip install -q git+https://github.com/openai/whisper.git\n",
        "# !pip install -q groq ffmpeg-python\n",
        "\n",
        "# import os\n",
        "# import ffmpeg\n",
        "# import whisper\n",
        "# from groq import Groq\n",
        "# from google.colab import files, userdata\n",
        "\n",
        "# Get the API key from user data\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_TOKEN')\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "\n",
        "# Upload the audio or video file\n",
        "uploaded = files.upload()  # This will allow you to upload files from your local system.\n",
        "\n",
        "# Function to extract audio from video\n",
        "def extract_audio(video_path, audio_path=\"temp_audio.wav\"):\n",
        "    \"\"\"Extracts audio from video.\"\"\"\n",
        "    try:\n",
        "        # Run ffmpeg command with stderr capture for better error handling\n",
        "        ffmpeg.input(video_path).output(audio_path).run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
        "    except ffmpeg.Error as e:\n",
        "        print(\"FFmpeg error encountered:\")\n",
        "        print(e.stderr.decode() if e.stderr else e)\n",
        "    return audio_path\n",
        "\n",
        "# Function to transcribe audio to text using Whisper model\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes audio to text using Whisper model.\"\"\"\n",
        "    model = whisper.load_model(\"base\")  # Load the Whisper model\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Function to summarize text using Groq API\n",
        "def summarize_text(text):\n",
        "    \"\"\"Summarizes text using Groq API.\"\"\"\n",
        "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"Summarize the following text: {text}\"}],\n",
        "        model=\"llama3-8b-8192\"\n",
        "    )\n",
        "    summary = response.choices[0].message.content\n",
        "    return summary\n",
        "\n",
        "# Complete function to process audio or video\n",
        "def process_media(media_path):\n",
        "    \"\"\"Processes audio or video: extracts audio, transcribes it, and summarizes the transcription.\"\"\"\n",
        "    audio_path = None\n",
        "    try:\n",
        "        # Determine if the file is a video or audio based on the file extension\n",
        "        if media_path.endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
        "            # Step 1: Extract audio from video\n",
        "            audio_path = extract_audio(media_path)\n",
        "        else:\n",
        "            audio_path = media_path  # If it's already audio, use it as is\n",
        "\n",
        "        # Step 2: Transcribe audio to text\n",
        "        transcription = transcribe_audio(audio_path)\n",
        "        print(\"Transcription:\\n\", transcription)\n",
        "\n",
        "        # Step 3: Summarize transcription\n",
        "        summary = summarize_text(transcription)\n",
        "        print(\"Summary:\\n\", summary)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the media: {e}\")\n",
        "\n",
        "    return transcription, summary\n",
        "\n",
        "# Example usage: Process the uploaded media file\n",
        "for filename in uploaded.keys():\n",
        "    transcription, summary = process_media(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "f5RjjZnKcZ9u",
        "outputId": "a470b1df-c952-4b33-f361-d74cc1f6b7a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6482741-55af-4634-ad00-31f09d35e4cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6482741-55af-4634-ad00-31f09d35e4cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving output_audio.mp3 to output_audio (3).mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            "  Artificial Intelligence AI refers to the development of computer systems that can perform tasks that typically require human. Intelligence, such as learning, problem solving, decision making, and perception, AI systems are designed to simulate human thought processes, using algorithms and data to make decisions, reason, and interact with the environment. The term artificial intelligence was coined in 1956 by computer scientist John McCarthy. Who defined it as the science and engineering of making intelligent machines? Since then, AI has evolved significantly, with advances in technology, data storage, and computing power enabling the development of more sophisticated and capable AI systems. There are many ways to classify AI, but one common approach is to divide it into three categories. One, narrow or weak AI. Also known as, narrow intelligence, this type of AI is designed to perform a specific task or set. Of tasks, such as playing chess, recognizing faces, or understanding spoken language, these systems are typically rule based and rely on algorithms to make decisions. Two, general or strong AI. This type of AI is designed to perform any intellectual task that a human can. Such as learning, reasoning, and problem solving. General AI systems are still in the early stages of development. But they have the potential to revolutionize many industries and aspects of our lives. Three, superintelligence. This type of AI is hypothetical and refers to an AI system that is significantly more intelligent. Then humans, capable of learning and adapting at an exponential rate. Superintelligence is still a speculative concept. But it raises important questions about the potential risks and benefits of such a powerful technology. Now, let's dive into some of the key components and aspects of AI. Machine learning. Machine learning is a subfield of AI that involves training algorithms to learn from data. Without being explicitly programmed, these algorithms can recognize patterns, make predictions, and improve their performance over time. Deep learning. Deep learning is a subfield of machine learning that uses neural networks to analyze data. These networks are composed of multiple layers. Each processing the data in a different way. Deep learning has achieved state-of-the-art results in many areas. Such as image recognition and natural language processing. Natural language processing. NLP. NLP is a subfield of AI that involves the interaction between computers and humans using natural. Language. NLP algorithms can understand and generate human language. Either written or spoken. Computer vision. Computer vision is a subfield of AI that involves the analysis and interpretation of visual data. Such as images and videos. Computer vision algorithms can be used in applications such as facial recognition. Object detection. Autonomous driving. Automation. Automation is a key aspect of AI. Involving the use of software to automate repetitive. Mundane. Or dangerous tasks. Automation can be applied to various industries. Such as manufacturing. Healthcare. And finance. Robotics. Robotics is a field of AI that involves the development of machines that can interact with the physical world. Robots can be used in applications such as assembly lines. Logistics. And search and rescue. Human AI collaboration. Human AI collaboration is the field of AI that involves humans and machines working together to. Achieve a common goal. This can be applied in various industries. Such as healthcare. Finance. And education. Ethics and fairness. AI raises important ethical questions about bias. Fairness. And accountability. As AI systems become more pervasive. It is essential to ensure that they are designed and developed with ethical principles in mind. Challenges and limitations. AI is not without its challenges and limitations. Some of the key challenges include. Astrosk ethics and governance. Ensuring that AI systems are developed and used in an ethical and responsible manner. Astrosk explainability. Interpreting and understanding the decisions made by AI systems. Astrosk bias and fairness. Ensuring that AI systems do not perpetuate biases and are fair and unbiased. Astrosk data quality. Ensuring that the data used to train AI systems is accurate. Complete. And unbiased. Astrosk security. Protecting AI systems from cyber threats and malicious attacks. In conclusion, AI is a rapidly advancing field that has the potential to transform many aspects of our lives. Its applications are vast and its benefits are numerous. But it also raises important challenges and limitations. As AI continues to evolve. It is essential to consider its implications and ensure that it is developed and used in a responsible and ethical manner.\n",
            "Summary:\n",
            " The text provides an overview of Artificial Intelligence (AI), its evolution, and its various aspects. Here's a summary:\n",
            "\n",
            "**Definition and History**: AI refers to computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. The term was coined by computer scientist John McCarthy in 1956.\n",
            "\n",
            "**Types of AI**: AI can be classified into three categories: Narrow or Weak AI, General or Strong AI, and Superintelligence. General and Superintelligence are still in development, but they have the potential to revolutionize many industries and aspects of life.\n",
            "\n",
            "**Key Components and Aspects**: The text discusses various aspects of AI, including:\n",
            "\n",
            "1. Machine learning: training algorithms to learn from data without being explicitly programmed.\n",
            "2. Deep learning: a subfield of machine learning that uses neural networks to analyze data.\n",
            "3. Natural Language Processing (NLP): interactions between computers and humans using natural language.\n",
            "4. Computer vision: analysis and interpretation of visual data.\n",
            "5. Automation: using software to automate repetitive or dangerous tasks.\n",
            "6. Robotics: development of machines that can interact with the physical world.\n",
            "7. Human-AI collaboration: humans and machines working together to achieve a common goal.\n",
            "8. Ethics and fairness: ensuring that AI systems are designed and developed with ethical principles in mind.\n",
            "9. Challenges and limitations: including astro-sk ethics and governance, explainability, bias and fairness, data quality, and security.\n",
            "\n",
            "**Conclusion**: AI is a rapidly advancing field with vast applications and numerous benefits, but it also raises important challenges and limitations. As AI continues to evolve, it is essential to consider its implications and ensure that it is developed and used in a responsible and ethical manner.\n"
          ]
        }
      ]
    }
  ]
}